{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Overview of Transformers Library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Transformer</b> - a novel machine learning architecture for sequence modelling, able to outperform recurrent networks.\n",
    "\n",
    "During this development, research was also ongoing on training methods and LSTM architectures used for text classification with little labeled data.\n",
    "\n",
    "These events catalyzed modern transformers like BERT and GPT by combining the transformer architecture with unsupervised learning. This in turn created a large array of transformer models, each of which utilize similar architectures:\n",
    "- The encoder-decoder framework\n",
    "- Attention mechanisms\n",
    "- Transfer learning "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Framework\n",
    "\n",
    "First, returning back to RNNs:\n",
    "- Architectures that contain a feedback loop in the network connections that allows information to propagate from one step to another, idea for sequence data (NLP, time series, etc.)\n",
    "- At each step of the sequences, an RNN receives some input, feeds it through the network, and outputs a vector called the hidden state \n",
    "- At the same time, the model feeds some information back to itself through the feedback looop, which it can use in the next step \n",
    "- Still widely used for NLP tasks\n",
    "- Play an important in the development of machine translation systems, usually tackled with an encoder-decoder architecture\n",
    "\n",
    "<b>Encoder-Decoder:</b> A sequence-to-sequence architecture, where the input and output are both sequences of arbitrary length. \n",
    "- Encoder converts information from the input sequence into a numerical representation called the last hidden state \n",
    "- This is passed to the decoder, which generates the output sequence\n",
    "\n",
    "In practice there are usually many RNN layers in each encoder and decoder.\n",
    "\n",
    "One shortcoming of this architecture is the creation of an information bottleneck. The final hidden state has to represent the meaning of the whole input sequence, which is difficult to do with longer sequences, as meaning towards the beginning might be lost in the process of compressing everything into a single, fixed representation. \n",
    "\n",
    "We can counteract this bottleneck by allowing the decoder to have access to all of the encoder's hidden states - a general mechanism called <b>attention</b>, a key component in transformer architecture.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanisms\n",
    "\n",
    "Instead of producing a single hidden state for the input sequence, the encoder outputs a hidden state at each step that the decoder can access. But, using all of these would create a huge input for the decoder, so some mechanism is required to prioritize which states to use. Attention allows the decoder to assign different weights, or attention, to each of the encoder states at every decoding timestep.\n",
    "\n",
    "By focusing on which input tokens are the most relevant at each time step, attention-based models are able to learn nontrivial alignments between words in a generated translation and those in a source sentence. \n",
    "\n",
    "This tasks like translation to be performed much more accurately, but there were still major shortcomings with using recurrent models for the encoder and the decoder: the computations are inherently sequential and cannot be parallelized across the input sequence. \n",
    "\n",
    "So, transforms removed recurrence entirely and instead shifted to a concept called self-attention. It's basic idea is to allow attention to operate on all states in the same layer of the network. The encoder and decoder each have their own self-attention mechanisms, whose outputs are fed to a feed-forward network. This can be trained must faster that recurrent models.\n",
    "\n",
    "Most transformers are trained on a large corpus of text from various languages, but in practical application we often do not have access to this amount of data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Transfer learning - where a network is trained on one general task, and then fine-tuned for a more specific downstream application, has been commonly used for computer vision. Despite this, it took many years before a training process for this was created for NLP applications. The general framework for this, created by ULMFiT, is:\n",
    "- *Pretraining*: The initial training objective for the model is to predict the next word based on the previous words, a task called language modeling. This approach requries no labeled data and can make use of abundantly available texts\n",
    "- *Domain Adaptation*: After pretraining, the model is adapted to an in-domain corpus. This still uses language modeling, but now the model has to predict words within the target corpus (ex. IMBD review dataset)\n",
    "- *Fine-Tuning*: The language model is then fine-tuned with a classification layer for the target task (ex. sentiment classification of movie reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace\n",
    "\n",
    "Traditionally, adapting pretrained models to new use cases was an intensive process that required a lot of specific engineering and custom logic. HuggingFace provides a standardized interface to a wide range of transformer models as well as code and tools to adapt these to new uses. It supports Tensorflow, Pytorch, and JAX, and provides task-specific heads, making fine-tuning much easier. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Transformers Library Tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each NLP task starts with text, like this made up customer review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror\n",
    "that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve this issue, I demand \n",
    "an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1968b86e37fd4515904d7e1d4fca4385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af5a64fb5c64eeea3f8f8e85415a11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HF has downloaded the model weights from the HF Hub. The second time the pipeline is instantiated, the library will used the cached version instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.916535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.916535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only returns positive or negative, so the confidence of the opposite label is $1 - score$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78670c1415f4a9f853ef7888c4719d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84155a8b919947548497d25c1f23f8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943430289a4c401ebd88a337fbd15446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6086c86f89684897bab3531547f46d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.990799</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.558730</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.591302</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.680140</td>\n",
       "      <td>Decept</td>\n",
       "      <td>253</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.490222</td>\n",
       "      <td>##icons</td>\n",
       "      <td>259</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.782622</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>351</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.987765</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>368</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.810411</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>503</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.881700         Amazon      5   11\n",
       "1         MISC  0.990799  Optimus Prime     36   49\n",
       "2          LOC  0.999756        Germany     90   97\n",
       "3         MISC  0.558730           Mega    208  212\n",
       "4          PER  0.591302         ##tron    212  216\n",
       "5          ORG  0.680140         Decept    253  259\n",
       "6         MISC  0.490222        ##icons    259  264\n",
       "7         MISC  0.782622       Megatron    351  359\n",
       "8         MISC  0.987765  Optimus Prime    368  381\n",
       "9          PER  0.810411      Bumblebee    503  512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline('ner', aggregation_strategy='simple')\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detects all entities in the text and assigns them a category. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Answering**\n",
    "\n",
    "We provide the model with a context, as well as a question whose answer we'd like to extract from the context. The model returns the span of text that corresponds to the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640578</td>\n",
       "      <td>337</td>\n",
       "      <td>360</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.640578    337  360  an exchange of Megatron"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'what does the customer want?'\n",
    "reader = pipeline('question-answering')\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "outputs = summarizer(text, max_length=56, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4932177b0c40239d51fcc98b5c5d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de0ae4577dd4726b18f5eeded10a0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369a0067b5f94dfdbccdd54c757f38eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30435caffc214a0b8f4f0e63d25c4590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/750k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943e6bdafb134f95907c870dbf8159b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2aa6c7aa84a62aa42aabcd14a102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZQ848WR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:198: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime Action Figur aus Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich hoffe, Sie können mein Dilemma verstehen. Um dieses Problem zu lösen, Ich fordere einen Austausch von Megatron für die Optimus Prime Figur habe ich bestellt. Eingeschlossen sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, bald von Ihnen zu hören. Aufrichtig, Bumblebee.\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea8d966dc8144368f0639d08382b083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b48df014f5c4ec2a00b10c277e24c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be734f1f2982496ea869c1472f5fb029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror\n",
      "that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve this issue, I demand \n",
      "an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
      "\n",
      "Customer service response:\n",
      "Dear Bumblebee, I am sorry to hear that your order was mixed up. I received a request for a new Optimus Prime action figure that was not available on the B&E website in Germany. I asked for something like the Optimus Prime action figure, but this time it was a completely different toy. I wanted a better deal and needed a place to store mine. When I heard you were happy\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation')\n",
    "response = 'Dear Bumblebee, I am sorry to hear that your order was mixed up.'\n",
    "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Tokenizers\n",
    "\n",
    "Behind each of these models is a tokenizer which converts the raw text into smaller pieces called tokens - parts of words, or just characters (like punctuation). Transformers are trained on numerical representations of these tokens, so getting this right is critical to the NLP process. \n",
    "\n",
    "The HF tokenizers library provides many tokenization strategies and is very fast. It also takes fare of all pre- and postprocessing steps. Loading a tokenizer works the same way as loading a transformer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Transformer Challenges\n",
    "\n",
    "1. Language: NLP research is dominated by English\n",
    "2. Data Availability: Transfer learning can dramatically decrease the amount of labeled training data we need, but we sometimes still need a lot in instances where there is little\n",
    "3. Working with long documents: Self-attention works extremely well on paragraph-long texts, but becomes very expensive when moved to documents\n",
    "4. Opacity: As with other deep learning models, transformers are very opaque. It's difficult to unravel extactly why a model makes a certain prediction\n",
    "5. Bias: Transformer models are trained on text from the internet, which is all subject to bias and misrepresentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
